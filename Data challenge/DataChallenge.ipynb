{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Libraries}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from scipy import optimize\n",
    "from scipy.linalg import cho_factor, cho_solve\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Importing Dataset}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Data points\n",
    "Xte0 = pd.read_csv('Xte0.csv',index_col=\"Id\")\n",
    "Xte1 = pd.read_csv('Xte1.csv',index_col=\"Id\")\n",
    "Xte2 = pd.read_csv('Xte2.csv',index_col=\"Id\")\n",
    "Xte = pd.concat([Xte0,Xte1,Xte2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data points\n",
    "Xtr0 = pd.read_csv('Xtr0.csv',index_col=\"Id\")\n",
    "Xtr1 = pd.read_csv('Xtr1.csv',index_col=\"Id\")\n",
    "Xtr2 = pd.read_csv('Xtr2.csv',index_col=\"Id\")\n",
    "Xtr = pd.concat([Xtr0,Xtr1,Xtr2])\n",
    "\n",
    "# Training labels\n",
    "Ytr0 = pd.read_csv('Ytr0.csv',index_col=\"Id\")\n",
    "Ytr1 = pd.read_csv('Ytr1.csv',index_col=\"Id\")\n",
    "Ytr2 = pd.read_csv('Ytr2.csv',index_col=\"Id\")\n",
    "Ytr = pd.concat([Ytr0,Ytr1,Ytr2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr0_np=Xtr0.to_numpy().reshape(-1)\n",
    "Ytr0_np=Ytr0.to_numpy().reshape(-1)\n",
    "Xte0_np=Xte0.to_numpy().reshape(-1)\n",
    "\n",
    "Xtr1_np=Xtr1.to_numpy().reshape(-1)\n",
    "Ytr1_np=Ytr1.to_numpy().reshape(-1)\n",
    "Xte1_np=Xte1.to_numpy().reshape(-1)\n",
    "\n",
    "Xtr2_np=Xtr2.to_numpy().reshape(-1)\n",
    "Ytr2_np=Ytr2.to_numpy().reshape(-1)\n",
    "Xte2_np=Xte2.to_numpy().reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def seq_length(seq):\n",
    "    return len(seq)\n",
    "\n",
    "seq_len=Xtr['seq'].apply(seq_length)\n",
    "seq_len.value_counts().plot(kind='bar')\n",
    "plt.xticks(rotation=0)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Kernels}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textit{Spectrum Kernel}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "class DNATrieNode:\n",
    "    \"\"\"A node in the DNA sequence trie.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Each node has 4 children, one for each DNA base (A, C, G, T)\n",
    "        # Using a dictionary for clarity, but could use array for better performance\n",
    "        self.children = {'A': None, 'C': None, 'G': None, 'T': None}\n",
    "        # Sequences that contain the k-mer represented by the path to this node\n",
    "        self.sequence_counts = defaultdict(int)\n",
    "        \n",
    "\n",
    "class SpectrumKernel:\n",
    "    \"\"\"\n",
    "    Implementation of the spectrum kernel using a trie data structure for efficient\n",
    "    k-mer counting in DNA sequences.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,k=6):\n",
    "        \"\"\"\n",
    "        Initialize the spectrum kernel with a given k-mer length.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        k : int\n",
    "            Length of k-mers to consider\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        \n",
    "    def _insert_kmer(self,kmer,seq_idx):\n",
    "        \"\"\"\n",
    "        Insert a k-mer into the trie and associate it with a sequence index.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        kmer : str\n",
    "            The k-mer to insert\n",
    "        seq_idx : int\n",
    "            Index of the sequence containing this k-mer\n",
    "        \"\"\"\n",
    "        node = self.root\n",
    "        \n",
    "        # Traverse the trie, creating nodes as needed\n",
    "        for base in kmer:\n",
    "            if base not in 'ACGT':\n",
    "                return  # Skip k-mers with non-DNA characters\n",
    "                \n",
    "            if node.children[base] is None:\n",
    "                node.children[base] = DNATrieNode()\n",
    "            \n",
    "            node = node.children[base]\n",
    "        \n",
    "        # Increment the count for this sequence at the terminal node\n",
    "        node.sequence_counts[seq_idx] += 1\n",
    "        \n",
    "    def add_sequences(self, sequences):\n",
    "        \"\"\"\n",
    "        Add sequences to the trie by inserting the k-mers of each one. \n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        sequences : str\n",
    "            DNA sequences to add\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        int\n",
    "            Index of the added sequences\n",
    "        \"\"\"\n",
    "        for seq in range(len(sequences)):\n",
    "            sequence = sequences[seq]\n",
    "            seq_idx = len(self.sequences)\n",
    "            self.sequences.append(sequence)\n",
    "            \n",
    "            # Insert all k-mers from the sequence\n",
    "            for i in range(len(sequence) - self.k + 1):\n",
    "                kmer = sequence[i:i+self.k]\n",
    "                self._insert_kmer(kmer, seq_idx)\n",
    "            \n",
    "        return seq_idx\n",
    "    \n",
    "    def compute_kernel_matrix(self,X,Y):\n",
    "        \"\"\"\n",
    "        Compute the kernel matrix for all added sequences.\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        numpy.ndarray\n",
    "            Kernel matrix where K[i,j] is the similarity between sequences i and j\n",
    "        \"\"\"\n",
    "        self.root = DNATrieNode()\n",
    "        self.sequences = []\n",
    "\n",
    "        self.add_sequences(X)\n",
    "        self.add_sequences(Y)\n",
    "\n",
    "        n1 = len(X)\n",
    "        n2 = len(Y)\n",
    "        K = np.zeros([n1, n2])\n",
    "\n",
    "        # Traverse the trie and update the kernel matrix based on shared k-mers\n",
    "        def traverse_and_compute(node):\n",
    "            if not any(node.children.values()):\n",
    "                # We're at a leaf, calculate contribution to kernel matrix\n",
    "                counts = node.sequence_counts\n",
    "                for i in counts :\n",
    "                    for j in counts:\n",
    "                        if i<n1 and j>=n1:\n",
    "                            K[i, j-n1] += counts[i] * counts[j]\n",
    "                return\n",
    "            \n",
    "            # Recursive traversal\n",
    "            for base, child in node.children.items():\n",
    "                if child:\n",
    "                    traverse_and_compute(child)\n",
    "        \n",
    "        traverse_and_compute(self.root)\n",
    "        return K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textit{Substring Kernels}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def B(k,x1,x2,lmd=0.5):\n",
    "    n = len(x1)\n",
    "    dp1 = np.ones([1,n,n])\n",
    "    dp2 = np.zeros([k,n,n])\n",
    "    dp = np.concatenate([dp1,dp2],axis=0)\n",
    "    \n",
    "    for k_val in range(1,k+1):\n",
    "        if k_val == 1:\n",
    "            dp[k_val,0,0] = (x1[0]==x2[0])*(lmd**2)\n",
    "            for idx in range(1,n):\n",
    "                dp[k_val,idx,0] = (lmd**2) * dp[k_val,idx-1,0] + (x2[0]==x1[idx]) * (lmd**2)\n",
    "                dp[k_val,0,idx] = (lmd**2) * dp[k_val,idx-1,0] + (x1[0]==x2[idx]) * (lmd**2)\n",
    "        for i in range(1,n):\n",
    "            for j in range(1,n):\n",
    "                dp[k_val][i][j] = (lmd * dp[k_val][i-1][j] +\n",
    "                                   lmd * dp[k_val][i][j-1] -\n",
    "                                   lmd**2 * dp[k_val][i-1][j-1] +\n",
    "                                   (x1[i-1] == x2[j-1]) * lmd**2 * dp[k_val-1][i-1][j-1])\n",
    "    \n",
    "    return dp\n",
    "\n",
    "def SSKernel(k,x1,x2,lmd=0.5):\n",
    "    n = len(x1)\n",
    "    B_k = B(k-1, x1[:-1], x2[:-1], lmd)\n",
    "    K = 0 \n",
    "    for idx_x1 in range(k,n):\n",
    "        for idx_x2 in range(k,n):\n",
    "            K += (x2[idx_x2]==x1[idx_x1]) * B_k[k-1,idx_x1-1,idx_x2-1]\n",
    "    return K \n",
    "\n",
    "def SSKernel_Matrix(k,X,lmd=0.5):\n",
    "    K = np.zeros([len(X),len(X)])\n",
    "    for i in range(len(X)):\n",
    "        for j in range(i,len(X)):\n",
    "            K[i,j]=SSKernel(k,X[i],X[j],lmd)\n",
    "            K[j,i]=K[i,j]\n",
    "    return K "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Kernel Methods}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textit{Kernel Ridge Regression}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class KernelRidgeRegression(BaseEstimator, RegressorMixin):\n",
    "    \"\"\"\n",
    "    Custom implementation of Kernel Ridge Regression\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    kernel_fn : callable\n",
    "        The kernel function to use. Should take two arrays X and Y and return the kernel matrix.\n",
    "    alpha : float, default=1.0\n",
    "        Regularization strength. Larger values specify stronger regularization.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, kernel_fn, alpha=1.0):\n",
    "        self.kernel_fn = kernel_fn\n",
    "        self.alpha = alpha\n",
    "        self.X_train = None\n",
    "        self.dual_coef_ = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the kernel ridge regression model.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Training data\n",
    "        y : array-like of shape (n_samples,)\n",
    "            Target values\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        self : returns an instance of self.\n",
    "        \"\"\"\n",
    "        # Store training data\n",
    "        self.X_train = X\n",
    "        \n",
    "        # Compute the kernel matrix\n",
    "        K = self.kernel_fn(X, X)\n",
    "        \n",
    "        # Add regularization to the diagonal\n",
    "        K_reg = K + self.alpha * np.eye(K.shape[0])\n",
    "        \n",
    "        # Solve for dual coefficients: (K + αI)α = y\n",
    "        self.dual_coef_ = np.linalg.solve(K_reg, y)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict using the kernel ridge model.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Samples\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        y_pred : ndarray of shape (n_samples,)\n",
    "            Predicted values\n",
    "        \"\"\"\n",
    "        # Compute kernel between test points and training points\n",
    "        K_test = self.kernel_fn(X, self.X_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = K_test.dot(self.dual_coef_)\n",
    "        \n",
    "        return (y_pred>0) * 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textit{Support Vector Classifier}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelSVC:\n",
    "    \n",
    "    def __init__(self, C, kernel, epsilon = 1e-3):\n",
    "        self.type = 'non-linear'\n",
    "        self.C = C                               \n",
    "        self.kernel = kernel        \n",
    "        self.alpha = None\n",
    "        self.support = None # support vectors\n",
    "        self.epsilon = epsilon\n",
    "        self.norm_f = None\n",
    "       \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "       #### You might define here any variable needed for the rest of the code\n",
    "        N = len(y)\n",
    "        K = self.kernel(X,X) # the gram matrix \n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        # Lagrange dual problem\n",
    "        def loss(alpha):\n",
    "            s_1 = np.sum(alpha)\n",
    "\n",
    "            weighted_labels = y*alpha\n",
    "            s_2=np.dot(weighted_labels.T,np.dot(K,weighted_labels))\n",
    "\n",
    "            return  s_1-(1/2)*s_2\n",
    "\n",
    "        # Partial derivate of Ld on alpha\n",
    "        def grad_loss(alpha):\n",
    "            weighted_labels = y*alpha\n",
    "            return 1 - y * np.dot(K,weighted_labels)\n",
    "\n",
    "        # Constraints on alpha of the shape :\n",
    "        # -  d - C*alpha  = 0\n",
    "        # -  b - A*alpha >= 0\n",
    "\n",
    "        fun_eq = lambda alpha:  np.dot(y,alpha) # '''----------------function defining the equality constraint------------------'''        \n",
    "        jac_eq = lambda alpha:  y   #'''----------------jacobian wrt alpha of the  equality constraint------------------'''\n",
    "        fun_ineq = lambda alpha:  np.hstack([self.C-alpha,alpha]) # '''---------------function defining the inequality constraint-------------------'''     \n",
    "        jac_ineq = lambda alpha:  np.vstack([-np.eye(N),np.eye(N)]) # '''---------------jacobian wrt alpha of the  inequality constraint-------------------'''\n",
    "        \n",
    "        constraints = ({'type': 'eq',  'fun': fun_eq, 'jac': jac_eq},\n",
    "                       {'type': 'ineq', \n",
    "                        'fun': fun_ineq , \n",
    "                        'jac': jac_ineq})\n",
    "\n",
    "        optRes = optimize.minimize(fun=lambda alpha: loss(alpha),\n",
    "                                   x0=np.ones(N), \n",
    "                                   method='SLSQP', \n",
    "                                   jac=lambda alpha: grad_loss(alpha), \n",
    "                                   constraints=constraints)\n",
    "        self.alpha = optRes.x\n",
    "\n",
    "        ## Assign the required attributes\n",
    "\n",
    "        #'''------------------- A matrix with each row corresponding to support vectors ------------------'''\n",
    "\n",
    "        self.support =  X[self.alpha>0] \n",
    "\n",
    "        #''' -----------------offset of the classifier------------------ '''\n",
    "\n",
    "        ind1 = self.alpha>0\n",
    "        ind2 = self.alpha<self.C\n",
    "        ind_verif = ind1*ind2 # datapoints having their respective 0<alpha_i<C\n",
    "        indices = np.arange(N)[ind_verif]\n",
    "        f_opt = lambda i: np.dot(K[i],y*self.alpha)\n",
    "\n",
    "        self.b = np.mean(1/y[indices]-f_opt(indices)) \n",
    "\n",
    "        # '''------------------------RKHS norm of the function f ------------------------------'''\n",
    "\n",
    "        weighted_labels = y*self.alpha\n",
    "\n",
    "        self.norm_f = np.dot(weighted_labels.T,np.dot(K,weighted_labels)) \n",
    "\n",
    "    ### Implementation of the separting function $f$ \n",
    "    def separating_function(self,x):\n",
    "        # Input : matrix x of shape N data points times d dimension\n",
    "        # Output: vector of size N\n",
    "        K_pred = self.kernel(self.X,x).T\n",
    "        return np.dot(K_pred,self.alpha*self.y)\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\" Predict y values in {0, 1} \"\"\"\n",
    "        d = self.separating_function(X)\n",
    "        return (d+self.b> 0) * 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Training}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = SpectrumKernel().compute_kernel_matrix\n",
    "model = KernelRidgeRegression(kernel_fn=kernel,alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(Xtr0_np,Ytr0_np)\n",
    "Y_pred0=model.predict(Xte0_np) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(Xtr1_np,Ytr1_np)\n",
    "Y_pred1=model.predict(Xte1_np) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(Xtr2_np,Ytr2_np)\n",
    "Y_pred2=model.predict(Xte2_np) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.632"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(Y_pred0==Ytr0_np)/len(Ytr0_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Submission}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = np.concatenate([Y_pred0,Y_pred1,Y_pred2])\n",
    "submission = pd.DataFrame({\"Id\": range(len(Y_pred)), \"Bound\": Y_pred})\n",
    "submission.to_csv(\"submission_KRR_alpha=0.1.csv\",header=True,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nvedl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
